\section{Discussion}
\label{sec:discussion}
Considering the results in Figure \ref{fig:sources} and \ref{fig:sinks}, it can be seen that when $\mu = 1$, the particles move along the shortest path between each source and the sink, while even a small non-linearity where $\mu = 1.05$ shows a clear preference to share paths from the sources to the sink. Notable is also the difference in amount of time steps required to achieve a stable solution. Since the behaviour fundamentally changes when utilizing a $\mu > 1$ this is not so surprising. Non-linearity emphasizes the tendency to create big roads and suppresses small roads. Hence small roads will faster be eliminated in a non-linear simulation compared to a linear simulation where small roads, if not being on the shortest path, only will disappear by statistical properties, i.e. they will only be eliminated since it is more probable to take the shortest path than any other path. 

With the larger values of $\mu$, $1.4$ and $1.5$, this preference to share paths is much more clear judging by the result in Figure \ref{fig:sources}, but it is not clear that $1.5$ leads to a stronger effect than $1.4$. This may be due to the stochastic nature of the algorithm and due to the non-linear reinforcement, which means that differences in the early stages of the simulations may persist forever. This can also lead to slightly different solutions when running the simulation multiple times with the same parameter values.

When increasing $\mu$ and running the simulation on a graph with only one source and many sinks the network creating pattern breaks down. This can be explained by the fact that the non-linear simulation have multiple stable solutions as opposed to the linear simulation which only has one solution (shortest path). Due to the non-linearity the simulation can be stuck in a state where particles basically only are moving between some nodes, reinforcing the flow and conductivity for only those nodes and edges creating a feedback loop. This is a stable state where the non-linearity is strong enough to prohibit the simulation to find any other stable state. For low values of $\mu$ the stochastic diffusion of particles can overcome this phenomenon and instead find stable network patterns. 

The reason for this phenomenon not occurring for $\mu = 1.4$ and $\mu = 1.5$ when running on a graph with many sources and only one sink, seen in Figure \ref{fig:sources}, could be explained by a combination of the difference in production rate for the sources and the difference in distance to nearest source. The fact that the source in Figure \ref{fig:sink} have $20$ times higher production rate than the individual sources in Figure \ref{fig:sources} adds non-linearly to the local current-reinforcement increasing the chance of a stable feedback loop. The difference in distance to the nearest source could also add to the difference in the behavior. If there are sources evenly spread throughout the graph it is more probable for the sources to connect to each other due to the current-reinforcement. Hence if there are many sources it is basically enough that only one source finds the sink and all the other sources will connect to each other and form a network. This cannot happen in between sinks, since they have no tendency to connect to each other. When looking at city centre of the result presented in Figure \ref{fig:uppsala} the difficulty of creating networks in between sinks can also there be observed.

The simulation when run on the graph of Uppsala shows that the non-linear current-reinforced random walk simulates the traffic flow to a city quite well. Looking at the different residence areas it can be seen that they are drained of particles in a very natural way, everyone are seeking the big roads to faster transport themselves to the city centre. By running a simulation like this the necessary road sizes for sustaining traffic demands, or if to put a road block in a residence area to prohibit traffic flow through there can be predicted. This area could be much further investigated, this simulation is merely scraping the surface of possible road map simulations. An idea to deal with this problem could be to reduce the non-linear reinforcement for a node as the number of particle within that node increases. This could perhaps prohibit feedback loops.

Judging by the results presented in Figure \ref{fig:speed_size} the parallelisation gave significant speedup and sizeup. The resulting speedup is roughly $0.5$ times the number of cores, which is a good speedup considering that there are two synchronisations in each iteration of the algorithm. The sizeup is also good at almost $0.5$ times number of cores. The drop in speedup at $16$ cores can be due to that the servers \textit{vitsippa.it.uu.se} and \textit{tussilago.it.uu.se} are dual socket and therefore have non uniform memory access times. Since the servers each have $32$ cores, using $16$ of them might result in conflicts with other processes running on the servers, meaning that threads will be placed on both sockets which raises memory access times for some threads. This increases the execution time since all cores need to synchronise. The probability for this phenomena to happen increases with the number of cores being used.

The reason for the sizeup being less than the speed up is due to cache misses. Since the cache size relatively decreases when the problem size is increased there will be more cache misses for bigger problems, hence the sizeup will not be as great as the speedup. 

To improve performance of the implementation, it may be useful to weight each node in the graph partitioning according to the number of neighbours that each node has, since the computational demand scales with the number of neighbours. It may also help to dynamically re-partition the graph, taking advantage of the fact that no computations need to be performed at nodes that do not contain any particles. These changes would increase the difference in number of nodes assigned to each core, which would be problematic, considering that the current implementation assigns an equal number of nodes to each core and there may not be a simple way to assign a different number of nodes to each core using OpenMP. This problem could be solved by utilising POSIX Threads (Pthreads) instead of OpenMP. By using Pthreads the programmer is given more control over the specific work that is performed by each core. In this way nodes could be transferred between cores dynamically while still using a shared memory model.

A natural progression of this work is to introduce communication between cores that do not share memory, e.g. via message passing. This would likely only provide performance improvements for large problems, since it relies on higher-latency communication.