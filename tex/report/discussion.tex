\section{Discussion}
\label{sec:discussion}

\begin{itemize}
\item MPI
\item Interpretation of result with graph is inverted resp. not inverted
\item METIS weights, dynamic partitioning
\item Slowdown for many threads on tussilago and vitsippa
\item Tuning parameters for better performance plus strange phenomena when too high prod. rate
\item Comment on speedup and sizeup
\end{itemize}

Considering the results in Figure \ref{fig:sources}, it can be seen that when $\mu = 1$, the particles move along the shortest path between each source and the sink, while even a small non-linearity where $\mu = 1.05$ shows a clear preference to share paths from the sources to the sink. With the larger values of $\mu$, $1.4$ and $1.5$, this preference to share paths is much more clear, but it is not clear that $1.5$ leads to a stronger effect than $1.4$. This may be due to the stochastic nature of the algorithm and due to the non-linear reinforcement, which means that differences in the early stages of the simulations may persist forever. This can also lead to slightly different solutions when running the simulation with the same parameter values.


Judging by the results presented in Figure \ref{fig:speed_size} the parallelisation gave significant speedup and sizeup. The resulting speedup is roughly $0.5$ times the number of cores, which is a good speedup considering that there are two synchronisations in each iteration of the algorithm. The sizeup is also good at almost $0.5$ times number of cores. The drop in speedup at $16$ cores can be due to that the servers \textit{vitsippa.it.uu.se} and \textit{tussilago.it.uu.se} are dual socket and therefore have non uniform memory access times. Since the servers each have $32$ cores, using $16$ of them might result in conflicts with other processes running on the servers, meaning that threads will be placed on both sockets which raises memory access times for some threads. This increases the execution time since all cores need to synchronise. The probability for this phenomena to happen increases with the number of cores being used.

The reason for the sizeup being less than the speed up is due to cache misses. Since the cache size relatively decreases when the problem size is increased there will be more cache misses for bigger problems, hence the sizeup will not be as great as the speedup. 

To improve performance of the implementation, it may be useful to weight each node in the graph partitioning according to the number of neighbours that each node has, since the computational demand scales with the number of neighbours. It may also help to dynamically re-partition the graph, taking advantage of the fact that no computations need to be performed at nodes that do not contain any particles. These changes would increase the difference in number of nodes assigned to each core, which would be problematic, considering that the current implementation assigns an equal number of nodes to each core and there may not be a simple way to assign a different number of nodes to each core using OpenMP. This problem could be solved by utilising POSIX Threads (Pthreads) instead of OpenMP. By using Pthreads the programmer is given more control over the specific work that is performed by each core. In this way nodes could be transferred between cores dynamically while still using a shared memory model.

A natural progression of this work is to introduce communication between cores that do not share memory, e.g. via message passing. This would likely only provide performance improvements for large problems, since it relies on higher-latency communication.